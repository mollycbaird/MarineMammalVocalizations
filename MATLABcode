 % LOAD AND TRIM THE DATA

nSpecies = 9;
nSamples = 25; % per species

species = {'Walrus','Harp_seal','Ross_seal',...
    'Killer_whale','Atlantic_spotted_dolphin','White_sided_dolphin',...
    'Humpback_whale','Sperm_whale','White_whale'};

data = cell(nSpecies,nSamples);
lengths = zeros(nSpecies,nSamples);
FSs = zeros(nSpecies,nSamples);

cd Final582DATA
for i = 1:nSpecies
    cd(species{i});
    files = dir('*.wav');
    for j = 1:nSamples
        [s,Fs] = audioread(files(j).name);
        l = length(s);
        slength = l/Fs;
        lengths(i,j) = slength;
        FSs(i,j) = Fs;
    end
    cd ..
end
cd ..

minLength = min(min(lengths));
minFs = min(min(FSs));

cd Final582DATA
for i = 1:nSpecies
    cd(species{i});
    files = dir('*.wav');
    for j = 1:nSamples
        [s,Fs] = audioread(files(j).name);
        s = s(1:floor(Fs*minLength));
        s = resample(s,minFs,Fs);
        data{i,j} = s;
    end
    cd ..
end
cd ..

%%
window = 100;
[H,W] = size(spectrogram(data{1,1},gausswin(window)));
X = zeros(H*W,nSpecies*nSamples);
counter = 0;

for i = 1:nSpecies
    for j = 1:nSamples
        counter = counter + 1;
        X(:,counter) = reshape(spectrogram(data{i,j},window),[],1);        
    end
end

% plotting a spectrogram
figure(1); clf
imagesc(flipud(abs(spectrogram(data{2,5},gausswin(window)))))
set(gca,'xtick',[])
set(gca,'ytick',[])
xlabel('Time')
ylabel('Frequency')
%title('Spectrogram of One Sound Clip')


X = abs(X);



%%    randomize the columns of X, within each 25 column chunk
X_r = [];
for i = 1:9
    M_new = [];                        
    k = 25*(i-1)+1;
    M_curr = X(:,k:k+25-1);
    y = randperm(25,25);
    for j = 1:25
        l = y(j);
        M_new = [M_new M_curr(:,l)];
    end
    X_r = [X_r M_new];
end

%% Take the SVD
[U,S,V] = svd(X_r-mean(X_r),'econ');        %take the SVD
s = diag(S)/max(diag(S));

clf

figure(1) 
plot(s(1:100), 'bo');
hold on
grid on
plot(cumsum(s(1:100))/sum(s), 'r', 'Linewidth',2)
title('Singular Values')
legend('Singular values','Cumulative energy', 'location', 'best')


%% Set Up the training data, test data, and label matrices

features = 1:100;

n = 20;     %training
m = 5;       %testing
label = [];
xtrain = [];
test = [];
truth = [];

%training
for i = 1:9
    label = [label; i*ones(n,1)];               %labels
    k = 25*(i-1)+1;
    xtrain = [xtrain; V(k:k+n-1,features)];       %training
    l = n+k; 
    test = [test; V(l:l+m-1,features)];         %test data
    truth = [truth; i*ones(m,1)];
end



%% %%%%%%%%%%%%%% SVM %%%%%%%%%%%%%%
Mdl = fitcecoc(xtrain,label);
test_labels = predict(Mdl,test);


CMdl = crossval(Mdl);                                       % cross-validate the model
classLoss = kfoldLoss(CMdl)                                 % compute class loss

overallAccuracy = sum(test_labels==truth)/length(truth)

T = zeros(9,9);
for i = 1:9
    T(:,i) = histcounts(test_labels(m*(i-1)+1:m*i),0.5:9.5);
end
T = T./m*100;
disp(T);

T = zeros(3,3);
for i = 1:3
    T(:,i) = histcounts(test_labels(3*m*(i-1)+1:3*m*i),[0.5 3.5 6.5 9.5]);
end
T = T./(3*m)*100;
disp(T);



%% %%%%%%%%%%%%  DENDROGRAM %%%%%%%%%%%%%%%%%%%

%%%% dendrogram for all 9
clf
Y = pdist(X_r,'euclidean');
Z = linkage(Y,'average');
thresh=0.001*max(Z(:,3));
[H,T,Outperm]=dendrogram(Z,225,'ColorThreshold',thresh);
set(gca,'xtick',[])
set(gca,'ytick',[])
%%
figure(2); clf
bar(Outperm,'b'), hold on
plot([0 225], [25 25], 'r:', [0 225], [50 50], 'r:', [0 225], [75 75],'r:', [0 225], [100 100], 'r:',[0 225], [125 125],'r:', [0 225], [150 150], 'r:',[0 225], [175 175], 'r:',[0 225], [200 200], 'r:','Linewidth',2)
plot([25 25], [0 225], 'r:', [50 50], [0 225], 'r:', [75 75], [0 225],'r:', [100 100], [0 225], 'r:',[125 125], [0 225], 'r:',[150 150], [0 225], 'r:',[175 175], [0 225],'r:', [200 200], [0 225], 'r:','Linewidth',2)
axis([0 225 0 225])
xlabel('Sound Clip')
ylabel('Clustering Outcome')
xticks(0:25:225)
yticks(0:25:225)




%% %%%%%%%%%%%%%% NB (naive bayes) %%%%%%%%%%%%%%
Mdl = fitcnb(xtrain,label);
test_labels = predict(Mdl,test);


CMdl = crossval(Mdl);                                       % cross-validate the model
classLoss = kfoldLoss(CMdl)                                 % compute class loss

overallAccuracy = sum(test_labels==truth)/length(truth)

T = zeros(9,9);
for i = 1:9
    T(:,i) = histcounts(test_labels(m*(i-1)+1:m*i),0.5:9.5);
end
T = T./m*100;
disp(T);

T = zeros(3,3);
for i = 1:3
    T(:,i) = histcounts(test_labels(3*m*(i-1)+1:3*m*i),[0.5 3.5 6.5 9.5]);
end
T = T./(3*m)*100;
disp(T);






%% %%%%%%%%%%% k-means %%%%%%%%%%%%%
clf
k = 9;
labels = kmeans(X_r',k);
histogram(labels)
xlabel('Cluster Label')
ylabel('Number of Sound Clips in Each Cluster')



%% %%%%%%%%%%%%% SVM FOR PINNIPEDS

features = 1:100;

n = 20;     %training
m = 5;       %testing
label = [];
xtrain = [];
test = [];
truth = [];

%training
for i = 1:3
    label = [label; i*ones(n,1)];               %labels
    k = 25*(i-1)+1;
    xtrain = [xtrain; V(k:k+n-1,features)];       %training
    l = n+k; 
    test = [test; V(l:l+m-1,features)];         %test data
    truth = [truth; i*ones(m,1)];
end

Mdl = fitcecoc(xtrain,label);
test_labels = predict(Mdl,test);


CMdl = crossval(Mdl);                                       % cross-validate the model
classLoss = kfoldLoss(CMdl)                                 % compute class loss

overallAccuracy = sum(test_labels==truth)/length(truth)


%% %%%%%%%%%%%%% SVM FOR DOLPHINS

features = 1:100;

n = 20;     %training
m = 5;       %testing
label = [];
xtrain = [];
test = [];
truth = [];

%training
for i = 4:6
    label = [label; i*ones(n,1)];               %labels
    k = 25*(i-1)+1;
    xtrain = [xtrain; V(k:k+n-1,features)];       %training
    l = n+k; 
    test = [test; V(l:l+m-1,features)];         %test data
    truth = [truth; i*ones(m,1)];
end

Mdl = fitcecoc(xtrain,label);
test_labels = predict(Mdl,test);


CMdl = crossval(Mdl);                                       % cross-validate the model
classLoss = kfoldLoss(CMdl)                                 % compute class loss

overallAccuracy = sum(test_labels==truth)/length(truth)


%% %%%%%%%%%%%%% SVM FOR WHALES

features = 1:100;

n = 20;     %training
m = 5;       %testing
label = [];
xtrain = [];
test = [];
truth = [];

%training
for i = 7:9
    label = [label; i*ones(n,1)];               %labels
    k = 25*(i-1)+1;
    xtrain = [xtrain; V(k:k+n-1,features)];       %training
    l = n+k; 
    test = [test; V(l:l+m-1,features)];         %test data
    truth = [truth; i*ones(m,1)];
end

Mdl = fitcecoc(xtrain,label);
test_labels = predict(Mdl,test);


CMdl = crossval(Mdl);                                       % cross-validate the model
classLoss = kfoldLoss(CMdl)                                 % compute class loss

overallAccuracy = sum(test_labels==truth)/length(truth)



%% %%%%%%%%%%%%% NB FOR PINNIPEDS

features = 1:100;

n = 20;     %training
m = 5;       %testing
label = [];
xtrain = [];
test = [];
truth = [];

%training
for i = 1:3
    label = [label; i*ones(n,1)];               %labels
    k = 25*(i-1)+1;
    xtrain = [xtrain; V(k:k+n-1,features)];       %training
    l = n+k; 
    test = [test; V(l:l+m-1,features)];         %test data
    truth = [truth; i*ones(m,1)];
end

Mdl = fitcnb(xtrain,label);
test_labels = predict(Mdl,test);


CMdl = crossval(Mdl);                                       % cross-validate the model
classLoss = kfoldLoss(CMdl)                                 % compute class loss

overallAccuracy = sum(test_labels==truth)/length(truth)



%% %%%%%%%%%%%%% NB FOR DOLPHINS

features = 1:100;

n = 20;     %training
m = 5;       %testing
label = [];
xtrain = [];
test = [];
truth = [];

%training
for i = 4:6
    label = [label; i*ones(n,1)];               %labels
    k = 25*(i-1)+1;
    xtrain = [xtrain; V(k:k+n-1,features)];       %training
    l = n+k; 
    test = [test; V(l:l+m-1,features)];         %test data
    truth = [truth; i*ones(m,1)];
end

Mdl = fitcnb(xtrain,label);
test_labels = predict(Mdl,test);


CMdl = crossval(Mdl);                                       % cross-validate the model
classLoss = kfoldLoss(CMdl)                                 % compute class loss

overallAccuracy = sum(test_labels==truth)/length(truth)



%% %%%%%%%%%%%%% NB FOR WHALES

features = 1:100;

n = 20;     %training
m = 5;       %testing
label = [];
xtrain = [];
test = [];
truth = [];

%training
for i = 7:9
    label = [label; i*ones(n,1)];               %labels
    k = 25*(i-1)+1;
    xtrain = [xtrain; V(k:k+n-1,features)];       %training
    l = n+k; 
    test = [test; V(l:l+m-1,features)];         %test data
    truth = [truth; i*ones(m,1)];
end

Mdl = fitcnb(xtrain,label);
test_labels = predict(Mdl,test);


CMdl = crossval(Mdl);                                       % cross-validate the model
classLoss = kfoldLoss(CMdl)                                 % compute class loss

overallAccuracy = sum(test_labels==truth)/length(truth)
